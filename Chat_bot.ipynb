{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPldjFh5WDOb6plInUTnW5J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nagapranavw/Chatbots/blob/Colab-backup/Chat_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUXjYWydk2fL"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "api_key_gpt = userdata.get('Gpt')\n",
        "api_key_gemini = userdata.get('gemini')\n",
        "\n",
        "openai_client = OpenAI(api_key=api_key_gpt)\n",
        "gemini_client = genai.Client(api_key=api_key_gemini)\n",
        "\n",
        "def gpt():\n",
        "  while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"gemini\"]:\n",
        "      gemini()\n",
        "      break\n",
        "    if user_input.lower() in [\"bye\", \"exit\", \"quit\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "\n",
        "    try:\n",
        "      response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-5-nano\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_input}]\n",
        "      )\n",
        "      print(\"GPT:\", response.choices[0].message.content)\n",
        "    except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "def gemini():\n",
        "  while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"gpt\", \"chatgpt\"]:\n",
        "      gpt()\n",
        "      break\n",
        "    if user_input.lower() in [\"bye\", \"exit\", \"quit\"]:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        response = gemini_client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=user_input,\n",
        "            config=types.GenerateContentConfig(\n",
        "            thinking_config=types.ThinkingConfig(thinking_budget=0)# Rember to enable to thinking based on need\n",
        "    ),\n",
        ")\n",
        "        print(\"gemini:\", response.text)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "bot_which = input(\"Please tell me which bot you would like to use chatgpt 5 nano or gemini flash. If you dont like the respones you can change later >\")\n",
        "if bot_which.lower() in [\"gemini\"]:\n",
        "  gemini()\n",
        "\n",
        "elif bot_which.lower() in [\"gpt\"]:\n",
        "  gpt()"
      ]
    }
  ]
}